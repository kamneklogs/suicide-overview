 //************************************************************************************
            //Para prueba
            List<Dictionary<string, object>> setToTraining = new List<Dictionary<string, object>>();
          
            setToTraining.Add(new Dictionary<string, object>() { { "color", "Green" }, { "diameter", 3 }, { "label", "Apple" } });
            setToTraining.Add(new Dictionary<string, object>() { { "color", "Yellow" }, { "diameter", 3 }, { "label", "Apple" } });
            setToTraining.Add(new Dictionary<string, object>() { { "color", "Red" }, { "diameter", 1 }, { "label", "Grape" } });
            setToTraining.Add(new Dictionary<string, object>() { { "color", "Red" }, { "diameter", 1 }, { "label", "Grape" } });
            setToTraining.Add(new Dictionary<string, object>() { { "color", "Yellow" }, { "diameter", 3 }, { "label", "Lemon" } });
            setToTraining.Add(new Dictionary<string, object>() { { "color", "Yellow" }, { "diameter", 1 }, { "label", "Lemon" } });

            Dictionary<string, int> variables = new Dictionary<string, int>();
            variables.Add("color", 1);
            variables.Add("diameter", 0);

            Tree myTree = new Tree(variables, "label");

            myTree.training(setToTraining);

            Dictionary<string, double> p = myTree.Classifier(new Dictionary<string, object>() { { "color", "Yellow" }, { "diameter", 1 } });

            Console.WriteLine("Probabilidad de limon "+p["Lemon"]);
            Console.WriteLine("Probabilidad de manzana " + p["Apple"]);
            Console.WriteLine("Probabilidad de uva " + p["Grape"]);

            myTree.printTree();

            Console.ReadLine();
            //************************************************************************************


 MasterClass mc = new MasterClass();

            List<Record> records = mc.RecordsByCountry("Republic of Korea");

            List<Dictionary<string, object>> setToTraining = new List<Dictionary<string, object>>();

            for (int i = 0; i < records.Count; i++)
            {
                setToTraining.Add(records[i].getData());
            }

            Dictionary<string, int> variables = new Dictionary<string, int>();

            variables.Add("Year", 0);
            variables.Add("Sex", 1);
            variables.Add("Generation", 1);

            Tree myTree = new Tree(variables, "Risk");

            myTree.training(setToTraining);

            Dictionary<string, double> p = myTree.Classifier(new Dictionary<string, object>() { { "Year", 2017 }, { "Sex", "male" }, { "Generation", "Millenials" } });

            foreach (string item in p.Keys)
            {
                Console.WriteLine("Probabilidad de riesgo " + item + ": " + (p[item] * 100) + "%");
            }


//****************Para pruebas con Accord********************************


 private static void realID3Example()
        {
            // In this example, we will be using the famous Play Tennis example by Tom Mitchell (1998).
            // In Mitchell's example, one would like to infer if a person would play tennis or not
            // based solely on four input variables. Those variables are all categorical, meaning that
            // there is no order between the possible values for the variable (i.e. there is no order
            // relationship between Sunny and Rain, one is not bigger nor smaller than the other, but are
            // just distinct). Moreover, the rows, or instances presented above represent days on which the
            // behavior of the person has been registered and annotated, pretty much building our set of
            // observation instances for learning:

            // Note: this example uses DataTables to represent the input data , but this is not required.
            DataTable data = new DataTable("Mitchell's Tennis Example");

            data.Columns.Add("Day", "Outlook", "Temperature", "Humidity", "Wind", "PlayTennis");
            data.Rows.Add("D1", "Sunny", "Hot", "High", "Weak", "No");
            data.Rows.Add("D2", "Sunny", "Hot", "High", "Strong", "No");
            data.Rows.Add("D3", "Overcast", "Hot", "High", "Weak", "Yes");
            data.Rows.Add("D4", "Rain", "Mild", "High", "Weak", "Yes");
            data.Rows.Add("D5", "Rain", "Cool", "Normal", "Weak", "Yes");
            data.Rows.Add("D6", "Rain", "Cool", "Normal", "Strong", "No");
            data.Rows.Add("D7", "Overcast", "Cool", "Normal", "Strong", "Yes");
            data.Rows.Add("D8", "Sunny", "Mild", "High", "Weak", "No");
            data.Rows.Add("D9", "Sunny", "Cool", "Normal", "Weak", "Yes");
            data.Rows.Add("D10", "Rain", "Mild", "Normal", "Weak", "Yes");
            data.Rows.Add("D11", "Sunny", "Mild", "Normal", "Strong", "Yes");
            data.Rows.Add("D12", "Overcast", "Mild", "High", "Strong", "Yes");
            data.Rows.Add("D13", "Overcast", "Hot", "Normal", "Weak", "Yes");
            data.Rows.Add("D14", "Rain", "Mild", "High", "Strong", "No");

            // In order to try to learn a decision tree, we will first convert this problem to a more simpler
            // representation. Since all variables are categories, it does not matter if they are represented
            // as strings, or numbers, since both are just symbols for the event they represent. Since numbers
            // are more easily representable than text string, we will convert the problem to use a discrete
            // alphabet through the use of a Accord.Statistics.Filters.Codification codebook.</para>

            // A codebook effectively transforms any distinct possible value for a variable into an integer
            // symbol. For example, “Sunny” could as well be represented by the integer label 0, “Overcast”
            // by “1”, Rain by “2”, and the same goes by for the other variables. So:</para>

            // Create a new codification codebook to
            // convert strings into integer symbols
            var codebook = new Codification(data);

            // Translate our training data into integer symbols using our codebook:
            DataTable symbols = codebook.Apply(data);
            int[][] inputs = symbols.ToJagged<int>("Outlook", "Temperature", "Humidity", "Wind");
            int[] outputs = symbols.ToArray<int>("PlayTennis");

            // For this task, in which we have only categorical variables, the simplest choice
            // to induce a decision tree is to use the ID3 algorithm by Quinlan. Let’s do it:

//****************SECTION TO TRAINNING THE TREE
            // Create a teacher ID3 algorithm
            var id3learning = new ID3Learning()
{
    // Now that we already have our learning input/ouput pairs, we should specify our
    // decision tree. We will be trying to build a tree to predict the last column, entitled
    // “PlayTennis”. For this, we will be using the “Outlook”, “Temperature”, “Humidity” and
    // “Wind” as predictors (variables which will we will use for our decision). Since those
    // are categorical, we must specify, at the moment of creation of our tree, the
    // characteristics of each of those variables. So:

    new DecisionVariable("Outlook",     3), // 3 possible values (Sunny, overcast, rain)
    new DecisionVariable("Temperature", 3), // 3 possible values (Hot, mild, cool)
    new DecisionVariable("Humidity",    2), // 2 possible values (High, normal)
    new DecisionVariable("Wind",        2)  // 2 possible values (Weak, strong)

    // Note: It is also possible to create a DecisionVariable[] from a codebook:
    // DecisionVariable[] attributes = DecisionVariable.FromCodebook(codebook);
};

            // Learn the training instances!
            DecisionTree tree = id3learning.Learn(inputs, outputs);

            // Compute the training error when predicting training instances
            double error = new ZeroOneLoss(outputs).Loss(tree.Decide(inputs));


//****************SECTION TO SIMULATE QUERY

            // The tree can now be queried for new examples through
            // its decide method. For example, we can create a query

            int[] query = codebook.Transform(new[,]
            {
                { "Outlook",     "Sunny"  },
                { "Temperature", "Hot"    },
                { "Humidity",    "High"   },
                { "Wind",        "Strong" }
            });

            // And then predict the label using
            int predicted = tree.Decide(query);  // result will be 0

            // We can translate it back to strings using
            string answer = codebook.Revert("PlayTennis", predicted); // Answer will be: "No"

            Console.WriteLine(answer);
        }
